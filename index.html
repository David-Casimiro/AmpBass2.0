<!DOCTYPE html>
<html lang="pt-BR">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1.0,maximum-scale=1.0"/>
<title>BassFX / Q-16 Live (Safari iOS Optimized)</title>

<!-- Tailwind CDN for quick styling -->
<script src="https://cdn.tailwindcss.com"></script>

<style>
  body { background: #020617; color: #e6f7ff; font-family: system-ui, -apple-system, sans-serif; }
  .card { background: linear-gradient(180deg,#041022,#021019); border:1px solid #11323f; border-radius:12px; padding:12px; }
  button{ transition:all .12s ease }
  canvas{ background:#000; border-radius:8px; display:block; width:100%; height:120px; }
  .small { font-size: .8rem; color:#9fd7ff; }
  .muted { color:#9ca3af }
</style>
</head>
<body class="p-4 max-w-lg mx-auto">

<header class="text-center mb-3">
  <h1 class="text-2xl font-bold">üéõÔ∏è Q-16 Live ‚Äî Web FX</h1>
  <p class="small">Otimiz. Safari iOS ‚Ä¢ Interface Teyun Q-16 ‚Ä¢ Low-latency pass-through</p>
</header>

<section class="card mb-3">
  <div class="flex gap-2 mb-2">
    <button id="openBtn" class="flex-1 py-2 rounded bg-emerald-600 font-semibold">Conectar & Ativar</button>
    <button id="refreshDevices" class="py-2 px-3 rounded bg-sky-600">Atualizar</button>
  </div>

  <label class="small muted">Selecionar Entrada (conecte Q-16 antes)</label>
  <select id="deviceSelect" class="w-full p-2 rounded bg-black/40 mb-2"></select>

  <div class="grid grid-cols-2 gap-2 mb-2">
    <button id="powerBtn" class="py-2 rounded bg-green-600">Power ON</button>
    <button id="muteBtn" class="py-2 rounded bg-yellow-500">MIC ON</button>
  </div>

  <div class="mb-2">
    <label class="small">Input Gain</label>
    <input id="gain" type="range" min="0" max="6" step="0.01" value="1" class="w-full">
  </div>

  <div>
    <label class="small">Output (Master)</label>
    <input id="master" type="range" min="0" max="1.2" step="0.01" value="0.9" class="w-full">
  </div>

  <p class="muted text-xs mt-2">Dica: conecte a Q-16 com o n√≠vel correto (Phones/AUX) e comece com ganho ‚âà 1. Use este app como camada de FX; para sinal cr√≠tico mantenha sa√≠da direta da mesa como redund√¢ncia.</p>
</section>

<section class="card mb-3">
  <label class="small">Visualizador (oscilloscope)</label>
  <canvas id="scope"></canvas>
</section>

<section class="text-xs text-gray-300 small">
  <p><strong>Requisitos / notas:</strong></p>
  <ul class="list-disc ml-4 muted">
    <li>iPhone iOS 14+ recomendado; Safari atual.</li>
    <li>Use adaptador oficial Lightning ‚Üî USB (Camera Adapter) ou USB-C direto.</li>
    <li>HTTPS √© obrigat√≥rio (GitHub Pages funciona).</li>
    <li>O navegador pode n√£o expor device labels at√© permiss√£o concedida.</li>
  </ul>
</section>

<footer class="text-center text-xs text-gray-400 mt-3">Q-16 Live ‚Ä¢ Web Audio ‚Ä¢ Experimental ‚Ä¢ Use em camadas</footer>

<script>
/* ============================
  Q-16 Optimized Web Audio (Safari iOS)
  - Uses AudioWorklet for light pass-through processing
  - device selection + minimal UI
  - tuned for low-latency use with class-compliant USB interface
============================ */

let audioContext = null;
let micStream = null;
let micSource = null;
let workletNode = null;
let analyser = null;

const openBtn = document.getElementById('openBtn');
const refreshBtn = document.getElementById('refreshDevices');
const deviceSelect = document.getElementById('deviceSelect');
const powerBtn = document.getElementById('powerBtn');
const muteBtn = document.getElementById('muteBtn');
const gainSlider = document.getElementById('gain');
const masterSlider = document.getElementById('master');
const canvas = document.getElementById('scope');
const ctx = canvas.getContext('2d');

let running = false;
let micOn = true;
let currentDeviceId = null;

// Small utility: sleep
const wait = ms => new Promise(r => setTimeout(r, ms));

/* ---------- AudioWorklet processor code (pass-through + gain) ----------
   We'll register this as a blob URL so fileless deployment is possible.
   The processor applies per-sample inputGain * masterGain.
   Keep it extremely minimal to reduce JS overhead.
-------------------------------------------------------------------------*/
const workletCode = `
class PassThroughProcessor extends AudioWorkletProcessor {
  static get parameterDescriptors() {
    return [
      { name: 'inputGain', defaultValue: 1, minValue: 0, maxValue: 10 },
      { name: 'masterGain', defaultValue: 0.9, minValue: 0, maxValue: 2 }
    ];
  }
  constructor() {
    super();
  }
  process(inputs, outputs, parameters) {
    const input = inputs[0];
    const output = outputs[0];
    if (!input || input.length === 0) return true;
    const inCh = input[0];
    const outCh = output[0];
    const ig = parameters.inputGain;
    const mg = parameters.masterGain;
    const frames = inCh.length;
    for (let i = 0; i < frames; i++) {
      const g = ig.length > 1 ? ig[i] : ig[0];
      const m = mg.length > 1 ? mg[i] : mg[0];
      outCh[i] = inCh[i] * g * m;
    }
    return true;
  }
}
registerProcessor('pass-through-processor', PassThroughProcessor);
`;

/* Create blob URL for the worklet script */
const workletBlob = new Blob([workletCode], { type: 'application/javascript' });
const workletUrl = URL.createObjectURL(workletBlob);

/* ---------- device enumeration ----------
   iOS Safari may not expose labels until permission is granted.
   We'll attempt to enumerate and populate the select.
-------------------------------------------*/
async function enumerateAudioInputs() {
  deviceSelect.innerHTML = '<option>Procurando...</option>';
  try {
    const devices = await navigator.mediaDevices.enumerateDevices();
    const inputs = devices.filter(d => d.kind === 'audioinput');
    deviceSelect.innerHTML = '';
    if (inputs.length === 0) {
      const opt = document.createElement('option');
      opt.value = '';
      opt.textContent = 'Nenhuma entrada detectada';
      deviceSelect.appendChild(opt);
      return;
    }
    inputs.forEach(d => {
      const opt = document.createElement('option');
      opt.value = d.deviceId;
      // label may be empty until permission, fall back to deviceId short label
      opt.textContent = d.label || ('device: ' + d.deviceId.substring(0,6));
      deviceSelect.appendChild(opt);
    });
  } catch (err) {
    console.warn('enumerateDevices error', err);
    deviceSelect.innerHTML = '<option value="">Erro ao listar dispositivos</option>';
  }
}

/* ---------- open / connect ---------- */
openBtn.onclick = async () => {
  // Make sure device is connected and user gesture
  try {
    if (!audioContext) {
      audioContext = new (window.AudioContext || window.webkitAudioContext)({
        latencyHint: 'interactive',
        sampleRate: 48000
      });
    }
    // Ensure worklet support
    if (!audioContext.audioWorklet) {
      alert('AudioWorklet n√£o suportado neste navegador. Tente Chrome ou Safari mais recente.');
      return;
    }
    // register worklet
    try {
      await audioContext.audioWorklet.addModule(workletUrl);
    } catch (err) {
      console.error('Worklet register error', err);
      alert('Falha ao registrar Worklet: ' + err.message);
      return;
    }

    // Request permission & stream ‚Äî prefer specific device if selected
    currentDeviceId = deviceSelect.value || undefined;

    // prepare constraints: prefer the selected deviceId
    const constraints = {
      audio: {
        deviceId: currentDeviceId ? { exact: currentDeviceId } : undefined,
        sampleRate: 48000,
        channelCount: 1,
        echoCancellation: false,
        noiseSuppression: false,
        autoGainControl: false,
        latency: 0
      }
    };

    micStream = await navigator.mediaDevices.getUserMedia(constraints);
    micSource = audioContext.createMediaStreamSource(micStream);

    // create worklet node
    workletNode = new AudioWorkletNode(audioContext, 'pass-through-processor', {
      numberOfInputs: 1,
      numberOfOutputs: 1,
      outputChannelCount: [1],
      parameterData: { inputGain: Number(gainSlider.value), masterGain: Number(masterSlider.value) }
    });

    // analyser for visual
    analyser = audioContext.createAnalyser();
    analyser.fftSize = 512;

    // connect chain: source -> worklet -> analyser -> destination
    micSource.connect(workletNode).connect(analyser).connect(audioContext.destination);

    running = true;
    powerBtn.textContent = 'Power ON ‚úì';
    powerBtn.classList.replace('bg-green-600','bg-green-800');
    openBtn.textContent = 'Conectado';
    openBtn.disabled = true;

    // update device list again (now labels available)
    await wait(200);
    await enumerateAudioInputs();

    drawLoop();
  } catch (err) {
    console.error('Erro conectar:', err);
    alert('Erro ao conectar: ' + (err.message || err));
  }
};

/* ---------- refresh devices ---------- */
refreshBtn.onclick = async () => {
  await enumerateAudioInputs();
};

// powerBtn toggles context suspend/resume (light control)
powerBtn.onclick = async () => {
  if (!audioContext) return alert('Conecte primeiro (Conectar & Ativar).');
  if (audioContext.state === 'suspended') {
    await audioContext.resume();
    powerBtn.textContent = 'Power ON ‚úì';
  } else {
    await audioContext.suspend();
    powerBtn.textContent = 'Power SUSP';
  }
};

// mute toggle: adjust parameter on worklet (no disconnect)
muteBtn.onclick = () => {
  if (!workletNode) return;
  micOn = !micOn;
  // set inputGain to 0 if muted, else to slider value
  const ig = micOn ? Number(gainSlider.value) : 0;
  workletNode.parameters.get('inputGain').setValueAtTime(ig, audioContext.currentTime);
  muteBtn.textContent = micOn ? 'MIC ON' : 'MIC OFF';
  muteBtn.classList.toggle('bg-gray-600', !micOn);
};

// gain / master controls update AudioWorklet parameters
gainSlider.oninput = () => {
  if (workletNode && micOn) {
    workletNode.parameters.get('inputGain').setValueAtTime(Number(gainSlider.value), audioContext.currentTime);
  }
};
masterSlider.oninput = () => {
  if (workletNode) {
    workletNode.parameters.get('masterGain').setValueAtTime(Number(masterSlider.value), audioContext.currentTime);
  }
};

/* ---------- visualizer (simple, low cost) ---------- */
function drawLoop() {
  if (!running || !analyser) return;
  requestAnimationFrame(drawLoop);

  // adjust canvas pixel ratio
  const dpr = window.devicePixelRatio || 1;
  const w = canvas.clientWidth;
  const h = canvas.clientHeight;
  canvas.width = Math.round(w * dpr);
  canvas.height = Math.round(h * dpr);
  ctx.setTransform(dpr, 0, 0, dpr, 0, 0);

  const bufferLen = analyser.fftSize;
  const data = new Uint8Array(bufferLen);
  analyser.getByteTimeDomainData(data);

  ctx.fillStyle = '#000';
  ctx.fillRect(0, 0, w, h);

  ctx.lineWidth = 2;
  ctx.strokeStyle = '#7dd3fc';
  ctx.beginPath();

  const sliceW = w / bufferLen;
  let x = 0;
  for (let i = 0; i < bufferLen; i += 4) { // step to reduce draw cost
    const v = data[i] / 128.0;
    const y = (v * h) / 2;
    if (i === 0) ctx.moveTo(x, y);
    else ctx.lineTo(x, y);
    x += sliceW * 4;
  }
  ctx.stroke();
}

/* ---------- initialization ---------- */
(async function init() {
  // attempt to populate devices (labels may be empty until permission)
  await enumerateAudioInputs();
})();

/* ---------- cleanup on page hide (helps mobile) ---------- */
window.addEventListener('pagehide', async () => {
  try {
    if (audioContext) await audioContext.close();
    if (micStream) micStream.getTracks().forEach(t => t.stop());
  } catch (e) {}
});

</script>
</body>
</html>
